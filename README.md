# ArtyLLama: AI-Powered Creative Platform for Interactive Content

![ArtyLLama Demo](artyllamaDemo.gif)

Welcome to **ArtyLLama**, a groundbreaking React-based platform that revolutionizes the way you create interactive content. By seamlessly integrating with multiple AI providers such as Ollama, OpenAI, and Anthropic, ArtyLLama empowers users to harness the power of Large Language Models (LLMs) to generate, iterate, and perfect their creative visions‚Äîall through natural language.

## üöÄ Features

- **Real-Time AI Chat Interface:**
  - Interact with AI models powered by Ollama, OpenAI, and Anthropic in real-time.
  
- **Dynamic Model Selection:**
  - Choose from a variety of AI models to best suit your project's needs.

- **Code Syntax Highlighting:**
  - Enjoy enhanced readability with syntax highlighting for multiple programming languages.

- **HTML Preview with Interactive Canvas:**
  - Visualize and interact with HTML content, complete with script support.

- **Responsive Design:**
  - Experience a sleek, responsive UI with expandable preview panels for optimal workflow.

- **Advanced Artifact Rendering:**
  - Render diverse content types, including HTML, SVG, and code snippets seamlessly.

- **SVG Rendering Support:**
  - Generate and display AI-created vector graphics with ease.

- **3D Games and Physical Simulations:**
  - Leverage **Three.js** to run immersive 3D games and accurate physical simulations directly within ArtyLLama.

- **Interactive Content Creation:**
  - Transform raw synthetic data from LLMs into engaging, interactive experiences.

- **Natural Language Interface:**
  - Create and iterate on your projects using intuitive natural language commands, making the creative process accessible to everyone.

- **Error Handling and Loading Indicators:**
  - Benefit from robust error management and real-time loading indicators for a smooth user experience.

- **Server-Side Streaming:**
  - Enjoy uninterrupted AI responses streamed directly from the server.

- **Customizable System Messages:**
  - Tailor system prompts to better align AI behavior with your creative goals.

- **Concurrent Server Operations:**
  - Run frontend and backend servers simultaneously for efficient development and deployment.

## üåü Vision

ArtyLLama is more than just a chat interface‚Äîit's a **powerful creative platform** designed to bridge the gap between raw synthetic data generated by Large Language Models and the creation of **interactive, immersive content**. Whether you're developing 3D games, conducting physical simulations, or crafting dynamic web experiences, ArtyLLama provides a versatile space where your creative ideas can flourish.

**Key Aspects of Our Vision:**

- **Natural Language Creativity:**
  - Empower users to create complex interactive content using simple, natural language instructions, eliminating the need for extensive coding knowledge.

- **Iterative Development:**
  - Facilitate continuous improvement and refinement of projects through an intuitive, conversational interface.

- **Alignment with User Vision:**
  - Ensure that the AI-generated content aligns closely with the user's creative intent, providing tools and flexibility to bring visions to life accurately.

- **Accessibility and Ease of Use:**
  - Make advanced AI-driven content creation accessible to a broader audience, from hobbyists to professional developers.

## üîß ArtyLLama Artifact Processing System

ArtyLLama employs a sophisticated artifact processing system to handle various types of AI-generated content. The following diagram illustrates the flow and processing steps for different artifact types:

![ArtyLLama Artifact Processing System](https://raw.githubusercontent.com/kroonen/artyllama/main/docs/artifact-processing-system.svg)

This system ensures that artifacts‚Äîfrom textual responses to complex 3D models‚Äîare efficiently processed and rendered in the user interface, enabling a seamless and interactive creative experience.

## üìã Prerequisites

Before you begin, ensure you have met the following requirements:

- **Docker:** For containerization and easy deployment.
- **Ollama:** Running locally or on an accessible server (for Ollama models).
- **API Keys:** For OpenAI and Anthropic (optional, if using these providers).

## üõ† Installation and Usage with Docker

1. **Clone the Repository:**
   ```bash
   git clone https://github.com/kroonen/artyllama.git
   cd artyllama
   ```

2.	**Build the Docker Image:**
   ```bash
   docker build -t artyllama:latest .
   ```

3.	**Run the Docker Container:**
   ```bash
   docker run -p 3000:80 -p 3001:3001 \
  -e OLLAMA_API_URL=http://host.docker.internal:11434 \
  -e ANTHROPIC_API_KEY=your_anthropic_key \
  -e OPENAI_API_KEY=your_openai_key \
  artyllama:latest
  ```
  Replace your_anthropic_key and your_openai_key with your actual API keys if you wish to utilize these services.
  **Note:** If you‚Äôre running on Linux, you might need to add the --add-host flag:
  ```bash
  docker run --add-host=host.docker.internal:host-gateway \
  -p 3000:80 -p 3001:3001 \
  -e OLLAMA_API_URL=http://host.docker.internal:11434 \
  -e ANTHROPIC_API_KEY=your_anthropic_key \
  -e OPENAI_API_KEY=your_openai_key \
  artyllama:latest
  ```
  
4.	Access the Application:
- **Frontend:** http://localhost:3000
- **Backend:** http://localhost:3001
- **Swagger UI:** http://localhost:3001/api-docs

## ‚öôÔ∏è Configuration

ArtyLLama now utilizes a configuration file instead of relying solely on environment variables. Follow these steps to set it up:

1.	**Rename the Configuration File:**
   ```bash
   mv user_preferences.json.example user_preferences.json
   ```

2. **Edit** user_preferences.json to Your Liking:
	   - Local Ollama API Connection:
	      - Choose to connect to your local Ollama API to run models locally.
	      - Important: If connecting locally, select the lite system prompt to prevent smaller models from being confused by the full system prompt.

## üßë‚Äçüíª Development Setup

For local development without Docker:

   1.	**Install Dependencies:**
   ```bash
   npm install
   ```

   2. **Create a .env File:**
      - In the root directory, create a .env file and populate it with your necessary environment variables.

   3. **Start the Development Servers:**
   ```bash
   npm run dev
   ```

## ü§ù Contributing

   Contributions to ArtyLLama are highly encouraged! Please read our Contributing Guidelines for details on our code of conduct and the process for submitting pull requests.

## üìÑ License

   This project is licensed under the MIT License - see the LICENSE file for details.

## üôè Acknowledgments

   AI Providers: Ollama, OpenAI, and Anthropic for providing robust AI backends.
   Frameworks and Libraries:
   React and Create React App for the frontend framework.
   Tailwind CSS for elegant and responsive styling.
   DOMPurify for secure HTML sanitization.
   Express.js for a reliable backend server.
   Three.js for 3D rendering and physical simulations.
   Community: All contributors shaping ArtyLLama into a versatile creative platform and Jean-Sebastien for testing!

## üí¨ Support

   If you find ArtyLLama valuable, please give it a ‚≠êÔ∏è on GitHub!

   For support or to report issues, please open an issue on the GitHub repository.

   ¬© 2024 ArtyLLama Research Project
